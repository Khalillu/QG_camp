# Transformer

## Attention机制

### 优点

1. 参数少：

   模型复杂度跟CNN、RNN相比，**复杂度更小，参数也更小**。所以对算力的要求也很小。

2. 速度快：

   Attention解决了RNN不能并行计算的问题。Attention机制**每一步计算不依赖于上一步的计算结果**，因此可以和CNN一样**并行处理**。

3. 效果好：

   在Attention机制引入之前，有一个问题大家一直很苦恼：长距离的信息会被弱化，就好像记忆能力弱的人，记不住过去的事情是一样的。

   Attention是**挑重点**，就算文本比较长，也能从中间抓住重点，不丢失重要的信息。

   如下图：

   ![img](https://pic4.zhimg.com/v2-09ed8523a47249430d6d49ade119924f_r.jpg)

### 特点

Attention模型的特点是Encoder不再将整个输入序列编码为固定长度的 向量C，而是编码成一个向量的序列。

![图解attention](https://easyai.tech/wp-content/uploads/2022/08/954a9-2019-10-28-attention.png)

这样，在产生每一个输出的时候，都能够做到充分利用输入序列携带的信息。

### 原理：

下面动图演示了Attention引入Encoder-Decoder框架之后，完成机器翻译任务的大致流程。

<video src="C:/Users/18929/Desktop/Attention%EF%BC%9ANeural%20Machine%20Translation.mp4"></video>

但Attention并不一定要在Encoder-Decoder框架下使用，它可以脱离Encoder-Decoder框架。

### 相关概念拓展：



#### Encoder-Decoder：

##### 定义：

Encoder-Decoder模型主要是NLP领域里的概念。它并不特指某种具体的算法，而是一类算法的统称。Encoder-Decoder算是一个通用的框架，在这个框架下可以使用不同的算法来解决不同的任务。

Encoder-Decoder 诠释机器学习的核心思路：

**“将现实问题转化为数学问题，通过求解数学问题，从而解决现实问题。”**

##### Encoder与 Decoder的作用

**Encoder**称作编码器，它的作用是**「将现实问题转化为数学问题」**

![Encoder将现实问题转化为数学问题](https://easyai.tech/wp-content/uploads/2022/08/6acff-2019-10-28-encoder.png)

**Decoder**称作解码器，它的作用是**「将现实问题转化为数学问题」**

![Decoder求解数学问题，并转化为现实世界的解决方案](https://easyai.tech/wp-content/uploads/2022/08/9cf5a-2019-10-28-decoder.png)

两个环节连接起来：

![图解Encoder-Decoder](https://easyai.tech/wp-content/uploads/2022/08/1bc89-2019-10-28-Encoder-Decoder.png)

##### 要点：

1. 不论输入和输出的长度是什么，中间的 “向量C”长度都是固定的。
2. 根据不同的任务可以选择不同的编码器和解码器（RNN or LSTM 、GRU）

##### 缺陷： 

可以类比为“压缩-解压”过程

**当输入信息太长时，会丢失掉一些信息**

#### Seq2Seq

##### 定义：

Seq2Seq(Sequence to Sequence)，输入一个序列，输出另一个序列。这种结构最重要的地方在于输入序列和输出序列的长度是可变的。

Eg：

![img](https://easyai.tech/wp-content/uploads/2022/08/da7fc-2019-10-28-nmt-model-fast.gif)

如上图：输入了 6 个汉字，输出了 3 个英文单词。输入和输出的长度不同。

##### 由来：

在 Seq2Seq 框架提出之前，深度神经网络在图像分类等问题上取得了非常好的效果。在其擅长解决的问题中，输入和输出通常都可以表示为**固定长度的向量**，如果长度稍有变化，会使用补零等操作。

然而许多重要的问题，例如机器翻译、语音识别、自动对话等，表示成序列后，其**长度事先并不知道**。因此如何突破先前深度神经网络的局限，使其可以适应这些场景，成为了13年以来的研究热点，Seq2Seq框架应运而生。

#### Seq2Seq与Encoder-Decoder之间的关系：

Seq2Seq（强调目的）不特指具体的方法，满足“输入序列、输出序列”的目的，都可以统称为Seq2Seq模型。

而Seq2Seq使用的具体方法基本都属于Encoder-Decoder模型（强调方法）的范畴。

#### LayNorm and BatchNorm

LayNorm，就是将一行的各个数据（一个样本）做正态分布中的标准化，即使均值为0，方差为1

（每一个特征向量-均值）/ 标准差

与之对应的使BatchNorm，使一列的各个数据（一个特征）做标准化，即使均值为0，方差为1

因此可以理解为将LayNorm先转置，然后使用BatchNorm，之后再转置回来

可以用三维平面来理解为

feature是一个词的向量表示（d=512），seq是你这一句话里有多少个词，batch是一共几句话

蓝色代表BatchNorm，橙色代表LayerNorm

BatchNorm：抖动会比较大，当token的词长度变化比较大的时候

这里说的是训练的时候是小批量均值和方差，样本数越小抖动越大。而预测的时候如果有一个长句子，就很难用之前的均值和方差来预测  

![image-20250710172214518](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710172214571.png)

BatchNormalization与LayNormalization在三维中的区别：
<img src="https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710193227066.png" alt="image-20250710193226924" style="zoom:67%;" />

Batch Normalization表示一整个蓝色的面

可以看出当每次做小批量且样本长度变化比较大的时候，均值与方差的抖动相对较大

预测时需要将全局的均值和方差记录下来，全局的均值方差，如果碰到一个样本长度很长（远远超出训练时样本长度）的样本时，此时记录下来的均值和方差效果就会变得差

而对于LayNormalization，每个样本都自己算自己的均值和方差，不需要存下全局的均值方差，相对而言更稳定

因为存在自注意力机制，所以既然用到了所有position，那么也会把未来position也放进去计算，所以我们需要用masking去遮住他们（以保证训练时和验证时保持一致），一般会用-∞来解决。

#### Attention功能：

注意力函数可以被描述为将查询和一组键值对映射到输出，其中查询、键、值和输出都是向量。输出可以被看做为一些值的加权和，每一个值都有分配的权重，该**权重**是由这个**Query和相应的关键字**的**相似度函数计算**。

因此，尽管KeyValue并没有改变，但是随着Query的改变，因为权重的分配不一样，导致输出结果会有不一样。

#### Scaled Dot-Product Attention

将每一个quaries和keys做内积，将其作为相似度

当两个向量做向量时，若其norm（范数，此处指模长）一样的话，内积越大，即余弦值越大，就表示这两个向量相似度越高；当内积为零时，即等于这两个向量正交，此时相似度为0



《Attention Is All You Need》：“我们将我们的特殊注意力称为“Scaled Dot-Product Attention”（图2）。输入由查询和维度为$d_k$的键以及维度为$d_v$的值组成。我们计算查询与所有键的点积，将每个键除以$\sqrt{d_k}$，然后应用softmax函数来获得值的权重。”

假设有n个key-value pair，此时query与每一个key-value pair做内积，即得到n个向量，然后再经过softmax之后得到n个非负的，且加起来等于1的权重。

因为qv很可能随着dk变大导致数量级很大，除以根号dk就是为了**约束**。看成一种**正则化**就可以

![image-20250710203708274](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710203708398.png)



#### Mask作用：

**防止在第t时刻看到第t时刻以后的token**



eg：对于第t时刻的query，即$q_t$，在做计算时，应该只能看$k_1$到$k_{t-1}$范围内的向量。因此此时$k_t$还不存在。但在注意力机制中，会看到所有的$k_i$。因此只要将在$k_t$和$k_t$之后的值全部都变成非常大的负数时，此时在softmax出来后对应的权重均为0，而不起效果。只有$k_{t-1}$​及之前的值对权重起效果。

![image-20250710210741613](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710210741644.png)

#### Multi-Head Attention：

我们发现，不是对$d_{model}$维的键、值和查询执行单个注意力函数，而是将查询、键和值分别线性投影h次到$d_k$、$d_k$和$d_v$​维。然后，对查询、键和值的每个投影版本并行执行注意力函数，得到维的输出值。然后将这些值连接起来，并再次进行投影，得到最终值。

![image-20250710210156253](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710210156283.png)

Query、Key、Value分别通过Linear层降维（投影），降到$d_k$、$d_k$、$d_v$维后，进入h个Scaled Dot-Product Attention中，得到h个output，再将输出向量全部合并在一起，最后做一次线性的投影，回到Multi-Head Attention。（此处的线性投影实际上就是让原矩阵乘以一个W矩阵）

训练得到的是权重矩阵，权重矩阵随机初始化。

#### Applications of Attention in our Model

第一个注意力层（Encoder编码器）和第二个注意力层（Decoder解码器）都是自注意力层，每一个向量经过注意力层处理后出来的向量与其本身相似，即权重最大。Masked（即第二层）则将每一个向量的后面的向量全部权重设置为0。

而第三个注意力层就不是自注意力层，因为它的输入不仅有第一个注意力层的输出（Value、Key），还有第二个注意力层的输出（Query）。

第三层则将编码器里面的一些输出（Key），根据想要的东西（也就是解码器的输入Query）给拎出来（即通过Key与Query的相似程度，挑选出想要的token ）

通俗的理解就是：

根据解码器输入的不同，根据当前的向量，去编码器挑选不同的感兴趣的东西

每一个Query所对应的输出常为512的向量

## Feed-forward

### Position-wise Feed-Forward Networks

#### 本质：

Fully connected feed-forward network，即MLP

position代表输入的序列中的词

即把一个MLP对每一个词作用一次，即对每一个词作用的是同样的一个MLP，作用在最后一个维度

#### 过程：

$W_1$将一个为512维的向量x投影到2048维，又由于整个网络结构具有一个残差连接（输入维度与输出维度相同），所以最后要通过$W_2$​将维度投影回512维

可以理解为单隐藏层的MLP，中间隐藏层将输入扩大四倍，最后输出时回到输入的大小

![image-20250710214630900](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710214630931.png)

#### Transformer与RNN在此处的区别：

Transformer先通过Attention层全局的聚合整个序列中的信息，然后再使用MLP做语义转换。（可并行处理）

而RNN则是将上一时刻的信息，整合当前信息，再使用MLP进行语义转换。（时序上不可并行处理）

## Embeddings and Softmax：

![image-20250710220655357](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710220655392.png)

### Embedding：

#### 作用：

Embedding通过学习一个长为d的向量来表示任何一个词。（token）

#### 要点：

1. 编码器与解码器（Encoder、Decoder）都需要一个Embedding，Softmax前面的线性层也需要一个Embedding，三个权重一样，训练起来相对简单
2. 学习embedding的时候，在不同程度上会将每一个向量的l2norm学成相对比较小的值。无论维度多大最后都会变小（维度越大的向量归一化后其单个值就越小）。因此维度越大，学习的权重值变小，但之后要加Positional Encoding。但Positional Encoding不会随着长度变长，而将norm固定住，因此需要乘以$\sqrt{d_{model}}$使输出的结果与Positional Encoding在Scale，即数据规模下相近。

## Positional Encoding：

由于Attention提取全局序列信息，没有时序性，因此在打乱输入后，仍只会有一种输出，因此要通过Positional Encoding，即输入中加入时序信息

![image-20250710221847193](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250710221847234.png)

将顺序信息直接将值输入进数据中，即向量相加，维度不变，长度方向变化

Attention会把输入序列的顺序打乱，但是输出的值是固定的；因此在每个数据点（token）中嵌入顺序信息。