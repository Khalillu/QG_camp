## 卷积神经网络：

#### 定义：

深度学习中广泛应用于**图像处理**的一种神经网络结构。

该神经网络一般由三个部分组成：

1. 卷积层：卷积就是将卷积核大小内的像素点，经过加权和，得到一个新的像素点。这个像素点在图像的层次上就可以反映原图像的特征。图像对应卷积的位置大小称为得到像素点对应的感受野。
2. 池化层
3. 全连接层

#### CNN变种模型：

##### LeNet：

###### 特点：

LeNet的主要贡献是提供了**卷积层和池化层**的组合结构，并且是最早使用CNN进行实际问题解决的模型之一。

###### 模块设计：

![img](https://picx.zhimg.com/v2-f37677d37986423d65dbf0ac19217543_r.jpg)

1. 第一模块：包含**5×5的6通道卷积和2×2的池化**。**卷积提取**图像中包含的**特征**模式（激活函数使用**sigmoid**），图像尺寸从32减小到28。经过池化层可以降低**输出特征图对空间位置的敏感性**（**平移不变性**），图像尺寸减到14。
2. 第二模块：和第一模块尺寸相同，通道数由6增加为16。卷积操作使图像尺寸减小到10，经过池化后变成5。
3. 第三模块：包含5×5的120通道卷积。卷积之后的图像尺寸减小到1，但是通道数增加为120。将经过第3次卷积提取到的特征图输入到全连接层。第一个全连接层的输出神经元的个数是64（**将第三次卷积之后的特征图flatten展平，之后变为一维向量**），第二个全连接层的输出神经元个数是分类标签的类别数，对于手写数字识别其大小是10。然后使用**Softmax**激活函数即可计算出每个类别的预测概率。、

###### 代码：

```python
# Model
import torch.nn as nn
import torch.nn.functional as F


class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        # 其中2d表示2 dimension，即二维
        # pytorch中的官方包，Conv2d表示卷积层，第一个in_channels表示输入的特征矩阵的深度，out_channels表示卷积核的个数，kernel_size代表卷积核的大小，stride默认为一，padding默认为零,若padding处后面为tuple，即元组(a,b)，表示在上下两行补a行0，在左右两行补b行0
        self.conv1 = nn.Conv2d(3, 16, 5)
        # MaxPool2d kernel为池化层的大小，stride为步长
        # 池化（即下采样，压缩参数）
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 5)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32*5*5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # relu激活函数，max(0,x)
        x = F.relu(self.conv1(x))    # input(3, 32, 32) output(16, 28, 28)
        x = self.pool1(x)            # output(16, 14, 14)
        x = F.relu(self.conv2(x))    # output(32, 10, 10)
        x = self.pool2(x)            # output(32, 5, 5)
        # 通过view函数将x转化为一维向量，-1代表第一个维度（即batch）
        x = x.view(-1, 32*5*5)       # output(32*5*5)
        x = F.relu(self.fc1(x))      # output(120)
        x = F.relu(self.fc2(x))      # output(84)
        x = self.fc3(x)              # output(10)
        return x
```

```python
# Train
import torch
import torchvision
import torch.nn as nn
from model import LeNet
import torch.optim as optim
import torchvision.transforms as transforms


def main():
    transform = transforms.Compose(
        # ToTensor将PIL Image转化为numpy.ndarray在[0,255]范围内的(H, W, C)，再转化为在[0,1]范围内的(C, H, W)
        [transforms.ToTensor(),
        # 将数据标准化
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    # 50000张训练图片
    # 第一次使用时要将download设置为True才会自动去下载数据集
    train_set = torchvision.datasets.CIFAR10(root='./data', train=True,
                                             download=False, transform=transform)
    # 每次加载一批数据集，每一批拿出36张图片
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=36,
                                               shuffle=True, num_workers=0)

    # 10000张验证图片
    # 第一次使用时要将download设置为True才会自动去下载数据集
    val_set = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=False, transform=transform)
    # shuffle决定是否在每一次取一批数据之后打乱索引
    val_loader = torch.utils.data.DataLoader(val_set, batch_size=5000,
                                             shuffle=False, num_workers=0)
    val_data_iter = iter(val_loader)
    val_image, val_label = next(val_data_iter)
    
    classes = ('plane', 'car', 'bird', 'cat',
                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

    net = LeNet()
    # nn.CrossEntropyLoss() 交叉熵损失函数
    loss_function = nn.CrossEntropyLoss()
    # 将net中的参数使用随机梯度算法Adam来进行更新
    optimizer = optim.Adam(net.parameters(), lr=0.001)

    for epoch in range(5):  # loop over the dataset multiple times

        running_loss = 0.0
        for step, data in enumerate(train_loader, start=0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data

            # zero the parameter gradients
            # 将历史损失梯度清零，防止对计算的历史梯度进行累加
            optimizer.zero_grad()
            # forward + backward + optimize
            outputs = net(inputs)
            loss = loss_function(outputs, labels)
            # loss.backward() 进行反向传播
            loss.backward()
            # 而optimizer.step()用于参数的更新
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if step % 500 == 499:    # print every 500 mini-batches
                # 此处为检验正确率，不需要计算每个结点的损失梯度
                with torch.no_grad():
                    outputs = net(val_image)  # [batch, 10]
                    # 第零维代表batch，第一维输出的十个结点中寻找最大值
                    # [1]代表index索引
                    predict_y = torch.max(outputs, dim=1)[1]
                    # 由于计算出来的是tenser张量，因此要将他转化为.item()，获取其中的数据
                    accuracy = torch.eq(predict_y, val_label).sum().item() / val_label.size(0)

                    print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %
                          (epoch + 1, step + 1, running_loss / 500, accuracy))
                    running_loss = 0.0

    print('Finished Training')

    save_path = './Lenet.pth'
    torch.save(net.state_dict(), save_path)


if __name__ == '__main__':
    main()
```

```python
# Predict
import torch
import torchvision.transforms as transforms
from PIL import Image

from model import LeNet


def main():
    transform = transforms.Compose(
        # 与train函数中相同
        # Resize是将图片的像素转化为32*32
        [transforms.Resize((32, 32)),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

    net = LeNet()
    net.load_state_dict(torch.load('Lenet.pth'))

    im = Image.open('2.jpg')
    # 将im中[H, W, C]的结构，转化为[C, H, W]的结构
    im = transform(im)  # [C, H, W]
    # 增加一个维度，N表示batch，即批量数
    im = torch.unsqueeze(im, dim=0)  # [N, C, H, W]

    with torch.no_grad():
        outputs = net(im)
        predict = torch.max(outputs, dim=1)[1].numpy()
        # predict = torch.softmax(outputs, dim=1)
        # 或者使用soft.max函数将输入进行处理
    # print(predict)
    print(classes[int(predict)])


if __name__ == '__main__':
    main()
```

##### AlexNet：

###### 特点：

AlexNet与LeNet相比，具有**更深的网络结构**，包含5层卷积和3层全连接，同时使用了如下三种方法改进模型的训练过程：

1. **数据增广**：深度学习中常用的一种处理方式，通过对训**练随机加一些变化**，比如**平移、缩放、裁剪、旋转、翻转或者增减亮度**等，产生一系列**跟原始图片相似但又不完全相同**的样本，从而**扩大训练数据集**。通过这种方式，可以随机改变训练样本，避免模型过度依赖于某些属性，能从一定程度上**抑制过拟合**。
2. 使用**Dropout**（**dropout(p=0.5)代表有50%概率使神经元失活**）抑制过拟合
3. 使用**ReLU**（本质为max(0,x)，导数简单且非负）激活函数减少梯度消失现象

引入了**ReLU激活函数**，加速了训练过程。使用了**Dropout技术**，减少了**过拟合**。使用了**数据增强和GPU加速**，是大规模训练变得可能。

###### 模块设计：

![img](https://pica.zhimg.com/v2-4b581f5519a3a71b9f8ea8f3b4f83f2c_r.jpg)

1. 第一模块：包含了11 x 11步长为4的96通道卷积以及一个**最大**池化
2. 第二模块：包含了5 x 5步的256通道卷积以及一个**最大**池化
3. 第三模块：包含了两个3 x 3的384通道以及一个3 x 3的256通道的卷积，后面加一个**最大**池化
4. 第四模块：包含了两个4096通道输入的全连接层，每个**全连接层后面加一个Dropout层**来抑制过拟合，以及还有最后一个1000通道的全连接层

###### 代码：

```python
# json形式保存的图像键值对
{
    "0": "daisy",
    "1": "dandelion",
    "2": "roses",
    "3": "sunflowers",
    "4": "tulips"
}
```

```python
# model
import torch.nn as nn
import torch


class AlexNet(nn.Module):
    def __init__(self, num_classes=1000, init_weights=False):
        super(AlexNet, self).__init__()
        # 使用nn.Sequential来精简代码（即封装网络层次比较多的模块）
        self.features = nn.Sequential(
            # 卷积或实例化过程中，若计算结果不为整数，则向下取整
            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 48为channel，即深度，而batch没有写出来
            # inplace = True pytorch通过某种方法，增加计算量但是能够降低内存使用容量的一种方法
            nn.ReLU(inplace=True),
            # 每经过一次卷积层，就需要进行一次ReLU激活函数
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27]
            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]
            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]
            nn.ReLU(inplace=True),
            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]
            nn.ReLU(inplace=True),
            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]
        )
        # 分类器，包含三个全连接层
        self.classifier = nn.Sequential(
            # p代表随机失活的比例
            nn.Dropout(p=0.5),
            # Pytorch中常常将channel放在首位，因此第一位为128
            # 每经过一次全连接层，也需要进行一次ReLU函数激活
            nn.Linear(128 * 6 * 6, 2048),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            # 全连接层的输入即等于上一层的输出
            nn.Linear(2048, 2048),
            nn.ReLU(inplace=True),
            # num_classes代表我们需要输出的类别个数
            nn.Linear(2048, num_classes),
        )
        # 初始化权重
        if init_weights:
            self._initialize_weights()

    # 正向传播
    def forward(self, x):
        # 调用以上模块封装
        x = self.features(x)
        # tensor通道排列顺序(batch, channel, height, width)
        # flatten展平，从index=1的维度
        x = torch.flatten(x, start_dim=1)
        # 将它输入到分类结构当中，即三个全连接层
        x = self.classifier(x)
        return x

    def _initialize_weights(self):
        # self.modules的继承自nn.module
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                # 一般Pytorch直接
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            # 若传进来的实例为全连接层，则使用normal
            elif isinstance(m, nn.Linear):
                # 通过一个正态分布来给权重进行赋值，均值为0，方差为0.01
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
```

```python
# train
import os
import sys
import json

import torch
import torch.nn as nn
from torchvision import transforms, datasets, utils
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
from tqdm import tqdm

from model import AlexNet


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    data_transform = {
        # RandomResizedCrop随机裁剪，将其裁剪到224*224像素大小
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     # 随机反转
                                     transforms.RandomHorizontalFlip(),
                                     # 转化为tensor
                                     transforms.ToTensor(),
                                     # 进行标准化处理
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
        "val": transforms.Compose([transforms.Resize((224, 224)),  # cannot 224, must (224, 224)
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}

    # "..表示返回上层目录 ..//..表示返回上上层目录"
    data_root = os.path.abspath(os.path.join(os.getcwd(), "../.."))  # get data root path
    image_path = r"D:\Pycharm\PyCharm 2024.3.1.1\deep-learning-for-image-processing-master\data_set\flower_data"  # flower data set path
    assert os.path.exists(image_path), "{} path does not exist.".format(image_path)
    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                        # 以上预处理函数
                                         transform=data_transform["train"])
    train_num = len(train_dataset)

    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
    flower_list = train_dataset.class_to_idx
    # 遍历刚才所获得的字典，将key和value值反过来，即将键和值相反
    # 以上处理之后，在预测完之后，返回给我们的索引就能直接通过字典得到它所对应的类别
    cla_dict = dict((val, key) for key, val in flower_list.items())
    # write dict into json file
    # 将cla_dict进行编码成json的方式
    json_str = json.dumps(cla_dict, indent=4)
    # 生成json文件
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 32
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               # 加载数据所使用的线程个数
                                               num_workers=nw)
    # 通过imagefolder载入测试集，同样传入测试集所对应的预处理参数，统计测试集的文件个数
    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
    val_num = len(validate_dataset)
    # 载入测试集
    validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=4, shuffle=False,
                                                  num_workers=nw)

    print("using {} images for training, {} images for validation.".format(train_num,
                                                                           val_num))
    # test_data_iter = iter(validate_loader)
    # test_image, test_label = test_data_iter.next()
    #
    # def imshow(img):
    #     img = img / 2 + 0.5  # unnormalize
    #     plt.imshow(np.transpose(npimg, (1, 2, 0)))
    #     npimg = img.numpy()
    #     plt.show()
    #
    # print(' '.join('%5s' % cla_dict[test_label[j].item()] for j in range(4)))
    # imshow(utils.make_grid(test_image))

    net = AlexNet(num_classes=5, init_weights=True)

    net.to(device)
    # 交叉熵损失函数
    loss_function = nn.CrossEntropyLoss()
    # pata = list(net.parameters())
    optimizer = optim.Adam(net.parameters(), lr=0.0002)

    epochs = 10
    save_path = './AlexNet.pth'
    # 为了能保存准确率最高的模型，因此有best_acc
    best_acc = 0.0
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        # 通过net.train与net.eval管理我们的dropout方法
        # net.train()打开dropout
        net.train()
        # 统计平均损失
        running_loss = 0.0
        train_bar = tqdm(train_loader, file=sys.stdout)
        for step, data in enumerate(train_bar):
            images, labels = data
            optimizer.zero_grad()
            outputs = net(images.to(device))
            loss = loss_function(outputs, labels.to(device))
            loss.backward()
            # 通过以上获得的损失信息，来更新每一个结点的参数
            optimizer.step()

            # print statistics
            # 打印训练进度
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)

        # validate
        # net.eval()关闭dropout
        net.eval()
        acc = 0.0  # accumulate accurate number / epoch
        # 禁止pytorch对参数进行跟踪
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))

        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)

    print('Finished Training')


if __name__ == '__main__':
    main()
```

```python
# predict
import os
import json

import torch
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

from model import AlexNet


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    data_transform = transforms.Compose(
        [transforms.Resize((224, 224)),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    # load image
    img_path = "../tulip.jpg"
    assert os.path.exists(img_path), "file: '{}' dose not exist.".format(img_path)
    img = Image.open(img_path)

    plt.imshow(img)
    # [N, C, H, W]
    # 预处理过程中，已将channel维度提到最前面
    img = data_transform(img)
    # expand batch dimension
    # batch,channel,height,width四个维度
    img = torch.unsqueeze(img, dim=0)

    # read class_indict
    json_path = 'class_indices.json'
    assert os.path.exists(json_path), "file: '{}' dose not exist.".format(json_path)

    with open(json_path, "r") as f:
        # 索引对应的类别名称，然后解码，结成我们所需要使用的字典
        class_indict = json.load(f)

    # create model
    # 然后初始化网络，载入网络模型
    model = AlexNet(num_classes=5).to(device)

    # load model weights
    weights_path = "./AlexNet.pth"
    assert os.path.exists(weights_path), "file: '{}' dose not exist.".format(weights_path)
    model.load_state_dict(torch.load(weights_path))

    model.eval()
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu()
        predict = torch.softmax(output, dim=0)
        predict_cla = torch.argmax(predict).numpy()

    print_res = "class: {}   prob: {:.3}".format(class_indict[str(predict_cla)],
                                                 predict[predict_cla].numpy())
    plt.title(print_res)
    for i in range(len(predict)):
        print("class: {:10}   prob: {:.3}".format(class_indict[str(i)],
                                                  predict[i].numpy()))
    plt.show()


if __name__ == '__main__':
    main()
```

##### VGG：

###### 特点：

网络深度较大，既有16层和19层。采用了**非常规则**的结构，全部使用**3*3**的卷积核。通过堆叠多个3*3的卷积核来替代大尺度卷积核，以此来减少所需参数

论文提及可以通过堆叠**两个3***3的卷积核替代5*5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核。优点是可以减少所需参数，而且拥有相同的感受野

###### 模块设计：

![img](https://pic4.zhimg.com/v2-9aa885a1de6a0986e443249602cf12a5_r.jpg)

1. 包含3×3的64通道卷积和一个最大池化
2. 包含3×3的128通道卷积和一个最大池化
3. 包含3×3的256通道卷积和一个最大池化
4. 包含3×3的512通道卷积和一个最大池化
5. 包含3×3的512通道卷积和一个最大池化
6. 展平为有4096通道数的全连接层和一个dropout层
7. 再次经过一个dropout层，最终变成通道数为1000的全连接层

###### 代码：

```python
# model
import torch.nn as nn
import torch

# official pretrain weights
model_urls = {
    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',
    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',
    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',
    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'
}


class VGG(nn.Module):
    # features代表make_futures生成的参数
    def __init__(self, features, num_classes=1000, init_weights=False):
        super(VGG, self).__init__()
        self.features = features
        # 分类网络结构
        self.classifier = nn.Sequential(
            # 512*7*7代表展平之后的元素个数
            nn.Linear(512*7*7, 4096),
            # Linear()展平为全连接层或者conv2()卷积之后都需要经过ReLU激活函数
            nn.ReLU(True),
            # dropout防止过拟合，以50%比例随机失活神经元
            nn.Dropout(p=0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(p=0.5),
            nn.Linear(4096, num_classes)
        )
        if init_weights:
            self._initialize_weights()

    def forward(self, x):
        # N x 3 x 224 x 224
        # 通过提取特征网络结构
        x = self.features(x)
        # N x 512 x 7 x 7
        # 从第一个维度开始展平，第零维是batch，第一维是channel，第二维是height，第三维是width
        x = torch.flatten(x, start_dim=1)
        # N x 512*7*7
        x = self.classifier(x)
        return x

    # 遍历神经网络的每一层，若遍历的神经网络为卷积层，那就要使用xavier取初始化卷积核的权重
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                nn.init.xavier_uniform_(m.weight)
                # 若使用了偏置，则将偏置初始化为零
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
                    # 若为全连接层，也是用xavier来初始化权重，将偏置设为零
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                # nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

    # 提取特征网络结构
def make_features(cfg: list):
    # 使用一个列表layers存储所需要的神经网络训练过程
    layers = []
    # RGB彩色图片，通道数为3
    in_channels = 3
    for v in cfg:
        if v == "M":
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
        else:
            # v不是M时，代表卷积核的个数
            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
            layers += [conv2d, nn.ReLU(True)]
            in_channels = v
            # 代表通过非关键字参数传入进去的
            # 层的顺序通过文件列表的顺序来生成
    return nn.Sequential(*layers)


cfgs = {
    # M代表最大池化
    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],
    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],
}

# **kwargs包含分类个数与初始化权重变量的布尔值
def vgg(model_name="vgg16", **kwargs):
    assert model_name in cfgs, "Warning: model number {} not in cfgs dict!".format(model_name)
    # 将VHH16的key值传入到字典中，就可以得到我们所对应的配置列表config
    cfg = cfgs[model_name]
    # 再通过实例化VGG，make_features(cfg)将列表cfg的特征提取出来，**kwargs中**表示可变长度字典变量
    model = VGG(make_features(cfg), **kwargs)
    return model
```

```python
# train
import os
import sys
import json

import torch
import torch.nn as nn
from torchvision import transforms, datasets
import torch.optim as optim
from tqdm import tqdm

from model import vgg


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    # 由于此模型是从头开始训练的，所以不需要减去RGB均值，若此模型是迁移学习再应用的话，就需要减去[123.68, 116.78, 103.94]这三个值
    data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
        "val": transforms.Compose([transforms.Resize((224, 224)),
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}

    data_root = os.path.abspath(os.path.join(os.getcwd(), "../.."))  # get data root path
    image_path = os.path.join(data_root, "data_set", "flower_data")  # flower data set path
    assert os.path.exists(image_path), "{} path does not exist.".format(image_path)
    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                         transform=data_transform["train"])
    train_num = len(train_dataset)

    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
    flower_list = train_dataset.class_to_idx
    cla_dict = dict((val, key) for key, val in flower_list.items())
    # write dict into json file
    json_str = json.dumps(cla_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 32
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    #定义数据生成器
    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               num_workers=nw)

    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
    val_num = len(validate_dataset)
    validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=batch_size, shuffle=False,
                                                  num_workers=nw)
    print("using {} images for training, {} images for validation.".format(train_num,
                                                                           val_num))

    # test_data_iter = iter(validate_loader)
    # test_image, test_label = test_data_iter.next()

    model_name = "vgg16"
    # VGG实例化应用
    net = vgg(model_name=model_name, num_classes=5, init_weights=True)
    net.to(device)
    loss_function = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.0001)

    epochs = 30
    best_acc = 0.0
    save_path = './{}Net.pth'.format(model_name)
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        running_loss = 0.0
        train_bar = tqdm(train_loader, file=sys.stdout)
        for step, data in enumerate(train_bar):
            images, labels = data
            optimizer.zero_grad()
            outputs = net(images.to(device))
            loss = loss_function(outputs, labels.to(device))
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)

        # validate
        net.eval()
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))

        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)

    print('Finished Training')


if __name__ == '__main__':
    main()
```

```python
# predict
import os
import json

import torch
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

from model import vgg


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    data_transform = transforms.Compose(
        [transforms.Resize((224, 224)),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    # load image
    img_path = "../tulip.jpg"
    assert os.path.exists(img_path), "file: '{}' dose not exist.".format(img_path)
    img = Image.open(img_path)
    plt.imshow(img)
    # [N, C, H, W]
    img = data_transform(img)
    # expand batch dimension
    img = torch.unsqueeze(img, dim=0)

    # read class_indict
    json_path = './class_indices.json'
    assert os.path.exists(json_path), "file: '{}' dose not exist.".format(json_path)

    with open(json_path, "r") as f:
        class_indict = json.load(f)
    
    # create model
    model = vgg(model_name="vgg16", num_classes=5).to(device)
    # load model weights
    weights_path = "./vgg16Net.pth"
    assert os.path.exists(weights_path), "file: '{}' dose not exist.".format(weights_path)
    model.load_state_dict(torch.load(weights_path, map_location=device))

    model.eval()
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu()
        predict = torch.softmax(output, dim=0)
        predict_cla = torch.argmax(predict).numpy()

    print_res = "class: {}   prob: {:.3}".format(class_indict[str(predict_cla)],
                                                 predict[predict_cla].numpy())
    plt.title(print_res)
    for i in range(len(predict)):
        print("class: {:10}   prob: {:.3}".format(class_indict[str(i)],
                                                  predict[i].numpy()))
    plt.show()


if __name__ == '__main__':
    main()
```



##### **GoogLeNet**:

![image-20250708210132900](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250708210140162.png)

###### 特点：

1. 引入了Inception结构（融合不同尺寸的特征信息）
2. 使用1×1的卷积核进行降维以及映射处理
3. 添加两个辅助分类器帮助训练
4. 丢弃全连接层，使用平均池化层（大大减少了模型参数）

###### Inception结构特点：

![img](https://pic1.zhimg.com/v2-546955ab5ef63ecf4f7d842dad55011e_r.jpg)

（a）是Inception模块的设计思想，使用3个不同大小的卷积核对输入图片进行卷积操作，并附加最大池化，将这4个操作的输出沿着通道这一维度进行拼接，构成的输出特征图将会包含经过不同大小的卷积核提取出来的特征。

Inception模块采用多通路(multi-path)的设计形式，每个支路使用不同大小的卷积核，最终输出特征图的通道数是每个支路输出通道数的总和，这将会导致输出通道数变得很大，尤其是使用多个Inception模块串联操作的时候，模型参数量会变得非常大。

空间分布范围更广的图像信息适合用较大的卷积核来提取其特征，而空间分布范围较小的图像信息则适合用较小的卷积核来提取其特征。

###### 模块设计：

**GoogLeNet的架构如 下图 所示，在主体卷积部分中使用5个模块（block），每个模块之间使用步幅为2的3 ×3最大池化层来减小输出高宽。**

![img](https://pic2.zhimg.com/v2-a4d5511fe70ccf72b3d69cc87bfae9a9_r.jpg)

1. 第一模块使用一个64通道的7 × 7卷积层
2. 第二模块使用2个卷积层:首先是64通道的1 × 1卷积层，然后是将通道增大3倍的3 × 3卷积层。
3. 第三模块串联2个完整的Inception块。
4. 第四模块串联了5个Inception块。
5. 第五模块串联了2 个Inception块。
6. 第五模块的后面紧跟输出层，使用全局平均池化 层来将每个通道的高和宽变成1，最后接上一个输出个数为标签类别数的全连接层。

并且：在原作者的论文中添加了图中所示的softmax1和softmax2两个辅助分类器，如下图所示，训练时将三个分类器的损失函数进行加权求和，以缓解梯度消失现象。这里的程序作了简化，没有加入辅助分类器。

###### 代码：

```python
# model
import torch.nn as nn
import torch
import torch.nn.functional as F


class GoogLeNet(nn.Module):
    # 分类个数、辅助分类器、权重
    def __init__(self, num_classes=1000, aux_logits=True, init_weights=False):
        super(GoogLeNet, self).__init__()
        self.aux_logits = aux_logits

        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)
        # 采用最大池化下采样计算公式发现得到的值为小数，当ceil_mode=True时，向上取整 ceil_mode=False时，向下取整
        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        self.conv2 = BasicConv2d(64, 64, kernel_size=1)
        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)
        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)
        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)
        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)
        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)
        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)
        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)
        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)
        self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True)

        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)
        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)

        # 若为true，则调用辅助分类器
        if self.aux_logits:
            self.aux1 = InceptionAux(512, num_classes)
            self.aux2 = InceptionAux(528, num_classes)

        # nn.AdaptiveAvgPool2d((1,1))中(1,1)代表输出矩阵必须要求高和宽均为1，不需要限制输入矩阵的长和宽
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(0.4)
        # 输入的展平后的向量结点个数是1024，输出的节点个数是num_classes，即点的各标签分类
        self.fc = nn.Linear(1024, num_classes)
        if init_weights:
            self._initialize_weights()

    def forward(self, x):
        # N x 3 x 224 x 224
        x = self.conv1(x)
        # N x 64 x 112 x 112
        x = self.maxpool1(x)
        # N x 64 x 56 x 56
        x = self.conv2(x)
        # N x 64 x 56 x 56
        x = self.conv3(x)
        # N x 192 x 56 x 56
        x = self.maxpool2(x)

        # N x 192 x 28 x 28
        x = self.inception3a(x)
        # N x 256 x 28 x 28
        x = self.inception3b(x)
        # N x 480 x 28 x 28
        x = self.maxpool3(x)
        # N x 480 x 14 x 14
        x = self.inception4a(x)
        # N x 512 x 14 x 14
        # 若self.training 与 self.aux_logits同时为true时，调用辅助分类器1
        if self.training and self.aux_logits:    # eval model lose this layer
            aux1 = self.aux1(x)

        x = self.inception4b(x)
        # N x 512 x 14 x 14
        x = self.inception4c(x)
        # N x 512 x 14 x 14
        x = self.inception4d(x)
        # N x 528 x 14 x 14
        if self.training and self.aux_logits:    # eval model lose this layer
            aux2 = self.aux2(x)

        x = self.inception4e(x)
        # N x 832 x 14 x 14
        x = self.maxpool4(x)
        # N x 832 x 7 x 7
        x = self.inception5a(x)
        # N x 832 x 7 x 7
        x = self.inception5b(x)
        # N x 1024 x 7 x 7

        x = self.avgpool(x)
        # N x 1024 x 1 x 1
        # 将channel展平
        x = torch.flatten(x, 1)
        # N x 1024
        x = self.dropout(x)
        x = self.fc(x)
        # N x 1000 (num_classes)
        # x代表最后一个辅助分类器，即辅助分类器3代表的值，aux2、aux1同理
        if self.training and self.aux_logits:   # eval model lose this layer
            return x, aux2, aux1
        return x

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)


class Inception(nn.Module):
    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):
        super(Inception, self).__init__()

        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)
        # 一个BasicConv2d无法表示网络结构块时可以使用nn.Sequential()复合两个或多个BasicConv2d来实现表示网络结构块
        self.branch2 = nn.Sequential(
            # ch3x3red的意思是channel3x3reduce，其实质是一个1x1的卷积核，作用是将Previous layer转化为深度更小的层，即参数更小的网络结构层，且不会改变特征层的高和宽
            BasicConv2d(in_channels, ch3x3red, kernel_size=1),
            # output_size = (input_size - 3 + 2*1)/1+1 = input_size
            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)   # 保证输出大小等于输入大小
        )

        self.branch3 = nn.Sequential(
            BasicConv2d(in_channels, ch5x5red, kernel_size=1),
            # 在官方的实现中，其实是3x3的kernel并不是5x5，这里我也懒得改了，具体可以参考下面的issue
            # Please see https://github.com/pytorch/vision/issues/906 for details.
            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)   # 保证输出大小等于输入大小
        )

        self.branch4 = nn.Sequential(
            # 保证输入矩阵的长和宽与输出矩阵的长和宽相等，因此我们需要将stride也就是步长，设置为1，padding=1
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
            # Pool2d操作（即池化）不会改变channels深度
            BasicConv2d(in_channels, pool_proj, kernel_size=1)
        )

    def forward(self, x):
        branch1 = self.branch1(x)
        branch2 = self.branch2(x)
        branch3 = self.branch3(x)
        branch4 = self.branch4(x)

        outputs = [branch1, branch2, branch3, branch4]
        # torch.cat(outputs, 1)中1代表channels，即tenser中的第一维
        return torch.cat(outputs, 1)


class InceptionAux(nn.Module):
    def __init__(self, in_channels, num_classes):
        super(InceptionAux, self).__init__()
        self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3)
        self.conv = BasicConv2d(in_channels, 128, kernel_size=1)  # output[batch, 128, 4, 4]

        self.fc1 = nn.Linear(2048, 1024)
        self.fc2 = nn.Linear(1024, num_classes)

    def forward(self, x):
        # aux1、aux2分别是辅助分类器1与2所输出的特征矩阵的维度
        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14
        x = self.averagePool(x)
        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4
        x = self.conv(x)
        # N x 128 x 4 x 4
        # 1 代表从channels维度开始展平
        x = torch.flatten(x, 1)
        # 0.5代表50%的失火率
        x = F.dropout(x, 0.5, training=self.training)
        # N x 2048
        x = F.relu(self.fc1(x), inplace=True)
        x = F.dropout(x, 0.5, training=self.training)
        # N x 1024
        x = self.fc2(x)
        # N x num_classes
        return x

# **kwargs表示其他参数，如padding、stride等
class BasicConv2d(nn.Module):
    # 输入输出矩阵深度
    def __init__(self, in_channels, out_channels, **kwargs):
        super(BasicConv2d, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.relu(x)
        return x
```

```python
# Train
import os
import sys
import json

import torch
import torch.nn as nn
from torchvision import transforms, datasets
import torch.optim as optim
from tqdm import tqdm

from model import GoogLeNet


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
        "val": transforms.Compose([transforms.Resize((224, 224)),
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}

    data_root = os.path.abspath(os.path.join(os.getcwd(), "../.."))  # get data root path
    image_path = os.path.join(data_root, "data_set", "flower_data")  # flower data set path
    assert os.path.exists(image_path), "{} path does not exist.".format(image_path)
    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                         transform=data_transform["train"])
    train_num = len(train_dataset)

    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
    flower_list = train_dataset.class_to_idx
    cla_dict = dict((val, key) for key, val in flower_list.items())
    # write dict into json file
    json_str = json.dumps(cla_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 32
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               num_workers=nw)

    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
    val_num = len(validate_dataset)
    validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=batch_size, shuffle=False,
                                                  num_workers=nw)

    print("using {} images for training, {} images for validation.".format(train_num,
                                                                           val_num))

    # test_data_iter = iter(validate_loader)
    # test_image, test_label = test_data_iter.next()

    net = GoogLeNet(num_classes=5, aux_logits=True, init_weights=True)
    # 如果要使用官方的预训练权重，注意是将权重载入官方的模型，不是我们自己实现的模型
    # 官方的模型中使用了bn层以及改了一些参数，不能混用
    # import torchvision
    # net = torchvision.models.googlenet(num_classes=5)
    # model_dict = net.state_dict()
    # # 预训练权重下载地址: https://download.pytorch.org/models/googlenet-1378be20.pth
    # pretrain_model = torch.load("googlenet.pth")
    # del_list = ["aux1.fc2.weight", "aux1.fc2.bias",
    #             "aux2.fc2.weight", "aux2.fc2.bias",
    #             "fc.weight", "fc.bias"]
    # pretrain_dict = {k: v for k, v in pretrain_model.items() if k not in del_list}
    # model_dict.update(pretrain_dict)
    # net.load_state_dict(model_dict)
    net.to(device)
    loss_function = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.0003)

    epochs = 30
    best_acc = 0.0
    save_path = './googleNet.pth'
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        running_loss = 0.0
        train_bar = tqdm(train_loader, file=sys.stdout)
        for step, data in enumerate(train_bar):
            images, labels = data
            optimizer.zero_grad()
            logits, aux_logits2, aux_logits1 = net(images.to(device))
            # 分别计算三个不同辅助分类器的结果的准确率
            loss0 = loss_function(logits, labels.to(device))
            loss1 = loss_function(aux_logits1, labels.to(device))
            loss2 = loss_function(aux_logits2, labels.to(device))
            # 0.3是权重
            loss = loss0 + loss1 * 0.3 + loss2 * 0.3
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)

        # validate
        # 当执行到net.eval()时，self.training的布尔值不再为真，因此上面向前传播的函数中，if语句不为真，因此辅助分类器1、2的结果不再输出，而是只输出主输出x
        net.eval()
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout)
            for val_data in val_bar:
                val_images, val_labels = val_data
                #
                outputs = net(val_images.to(device))  # eval model only have last output layer
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))

        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)

    print('Finished Training')


if __name__ == '__main__':
    main()
```

```python
# Predict
import os
import json

import torch
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

from model import GoogLeNet


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    data_transform = transforms.Compose(
        [transforms.Resize((224, 224)),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    # load image
    img_path = "../tulip.jpg"
    assert os.path.exists(img_path), "file: '{}' dose not exist.".format(img_path)
    img = Image.open(img_path)
    plt.imshow(img)
    # [N, C, H, W]
    img = data_transform(img)
    # expand batch dimension
    img = torch.unsqueeze(img, dim=0)

    # read class_indict
    json_path = './class_indices.json'
    assert os.path.exists(json_path), "file: '{}' dose not exist.".format(json_path)

    with open(json_path, "r") as f:
        class_indict = json.load(f)

    # create model
    model = GoogLeNet(num_classes=5, aux_logits=False).to(device)

    # load model weights
    weights_path = "./googleNet.pth"
    # strict=False（等于True时将会精准匹配当前模型和我们将要载入的权重模型），因为此时的GoogLeNet不含有辅助分类器，所以和我们保存起来的模型对比起来缺一些层结构，因此需要将strict转化为False
    assert os.path.exists(weights_path), "file: '{}' dose not exist.".format(weights_path)
    missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device),
                                                          strict=False)

    model.eval()
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu()
        predict = torch.softmax(output, dim=0)
        predict_cla = torch.argmax(predict).numpy()

    print_res = "class: {}   prob: {:.3}".format(class_indict[str(predict_cla)],
                                                 predict[predict_cla].numpy())
    plt.title(print_res)
    for i in range(len(predict)):
        print("class: {:10}   prob: {:.3}".format(class_indict[str(i)],
                                                  predict[i].numpy()))
    plt.show()


if __name__ == '__main__':
    main()
```

##### ***ResNet：***

引入了**残差连接**，使得网络可以非常深，**避免了梯度消失**。ResNet可以非常轻松地训练几百层甚至上千层的网络。

![image-20250407204625308](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250407204625402.png)

###### 步骤：

1. 读数据：将图片数据按照想要的格式读取到程序中
2. 载入模型 ：载入已经编写好的神经网络模型的结构
3. 训练模型：使用训练数据来对神经网络模型进行训练，得到一组参数
4. 验证模型：使用验证数据测试该轮训练出来的模型表现如何
5. 保存模型：将训练出来的参数以文件的形式保存到本地，便于测试时读取
6. 测试模型：检验模型的表现

###### ResNet结构特点：

当残差连接为实线时，代表此分支为主分支，而主分支与shortcut的输出特征矩阵shape必须相同

而当残差连接为虚线时，说明该分支的输出特征矩阵不一定要和shortcut的输出特征矩阵的shape相同

1. 右图左枝由于经过了步长为2的卷积核卷积，所以他的高和宽变为原来的一半，而卷积核个数为128，所以out_channels也应该为128
2. 右图右枝由于也经过了步长为2的128个卷积核卷积，因此同上变化

**需要将右图的输出，再输入到左图中，才能保证输出的shape相同**

![image-20250708223032938](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250708223033052.png)

###### ResNet重点：

* 定义H(x) = f(x) + x，有**f(x) = H(x) - x**，其中f(x)即为残差，在更新时残差的变化率大于普通映射，对变化更加敏感

* 新添加的层训练成**恒等映射**（identityfunction）**f(x) = x**

![image-20250410141206100](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250410141206222.png)

我们只需将**图7.6.2**中右图虚线框内上方的加权运算（如仿射）的**权重和偏置参数**设成**0**，那么f(x)即为**恒等映射**。实际中，当理想映射f(x)**极接近**于恒等映射时，残差映射也易于捕捉 恒等映射的细微波动。

如果想改变通道数，就需要引入一个**额外的1×1卷积层**来将输入变换成需要的形状后再做相加运算。

###### ResNet网络特点：

1. 超深的网络结构
2. 提出residual模块
3. 使用Batch Normalization加速训练（丢弃dropout）
4. (a)：表示增加网络的时候，将x映射成y=F(x)输出。
5. (b)：对(a)作了改进，输出y=F(x) + x这时不是直接学习输出特征y的表示，而是学习y - x（如下图所示）

![img](https://pic4.zhimg.com/v2-828b1a4eb077178f30243d1ec9305a6f_r.jpg)

下图表示出了ResNet-50的结构，一共包含49层卷积和1层全连接，所以被称为ResNet-50。

![img](https://pic2.zhimg.com/v2-4c70dc9d282aa106bc3bc3b24ba8c701_r.jpg)

###### Batch Normalization：

定义：

![image-20250709091425039](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250709091432209.png)

原理：

我们在图像预处理过程中通常会对图像进行**标准化**处理，这样能够**加速**网络的**收敛**，如下图所示，对于**Conv1**来说输入的就是**满足某一分布**的特征矩阵，但对于**Conv2**而言输入的**feature map**就**不一定满足**某一分布规律了（注意这里所说满足某一分布规律并不是指某一个feature map的数据要满足分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律）。而我们Batch Normalization的目的就是使我们的**feature map满足均值为0，方差为1**的分布规律。

![img](https://i-blog.csdnimg.cn/blog_migrate/38761f8e93c1f4ab647a7ccad2aba1f9.png)

使用BN时需要注意的问题
（1）训练时要将traning参数设置为True，在验证时将trainning参数设置为False。在pytorch中可通过创建模型的**model.train()和model.eval()**方法控制。

（2）batch size尽可能设置**大**点，设置小后表现可能很糟糕，设置的越大求的均值和方差越**接近**整个训练集的均值和方差。

（3）建议将**bn层**放在卷积层（**Conv**）和激活层（例如**Relu**）之间，且**卷积层**不要**使用偏置bias**，因为没有用，参考下图推理，即使使用了偏置bias求出的结果也是一样的![\bg_white \large y_{i}^{b}=y_{i}](https://private.codecogs.com/gif.latex?%5Cbg_white%20%5Clarge%20y_%7Bi%7D%5E%7Bb%7D%3Dy_%7Bi%7D)

[Batch Normalization详解以及pytorch实验_pytorch batch normalization-CSDN博客](https://blog.csdn.net/qq_37541097/article/details/104434557?ops_request_misc=elastic_search_misc&request_id=a8b9142c93ba7fec6ed7df2d10144d64&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-104434557-null-null.142^v102^pc_search_result_base3&utm_term=Batch Normalization详解&spm=1018.2226.3001.4187)

###### ResNeXt：

在ResNet网络结构的基础上，将卷积核分组进行卷积，然后将卷积之后的Feature map拼接加起来，优势是可以减少超参数的数量

![image-20250709103845149](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250709103845263.png)

![image-20250709104032233](https://khalillu.oss-cn-guangzhou.aliyuncs.com/khalillu/20250709104032375.png)

#### 卷积神经网络基本知识：

![img](https://i2.hdslb.com/bfs/note/8899965db90a92f2ab84e4cedc84d8f24e0b4914.jpg@690w_!web-note.webp)

##### **1.基本（以单通道为例进行学习）**

**什么是卷积？**

——把卷积核放在输入上进行滑窗，将当前卷积核覆盖范围内的输入与卷积核相乘，将值进行累加，得到当前位置的输出；（从数学角度：输入和卷积核的内积运算）；

**本质：融合多个像素值的信息输出一个像素值【下采样】**

**卷积层——提取图像的底层特征**

**池化层——防止过拟合，降维**

​					池化的本质就是采样，降维压缩

**全连接层——汇总卷积层和池化层得到的特征**

**padding——防止边缘的特征被忽略掉**

**上采样——又名放大图像、图像插值**

{主要目的：放大原图像，从而可以显示在更高分辨率的显示设备上；常用方法：双线性插值（在原有图像像素的基础上在像素点之间采用合适的插值算法 [基于边缘的插值、基于区域的图像插值] 插入新的元素，详细介绍的文章如下：“http://t.csdnimg.cn/dYbFb”）；反卷积；反池化}

反卷积（转置卷积）：将下图中的卷积看成是输入通过卷积核的透视，则反卷积就可以看成是输出通过卷积的透视；

![img](https://i2.hdslb.com/bfs/note/5ff638321f94eb93d541b211bd140a64e91cf3b7.png@690w_!web-note.webp)

通过反卷积得到的特征图与卷积输入的特征图像的大小并不相同——>卷积和反卷积并不是完全对等的可逆操作——>反卷积只能恢复尺寸，并不能恢复数值

此时的padding是指内部的空隙

**下采样——又名降采样、缩小图像**

{主要目的：使得图像符合显示区域的大小；生成对应图像的缩略图}

原理：图像I的尺寸为M*N，对其进行s倍的下采样，即得到（M/s）*（N/s）尺寸的分辨率图像，注意：s要是M和N的公约数；如果是矩阵形式的图像，就是把原始图像s*s窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值或者最大值（即池化操作）

**感受野——**特征图上的某个点能看到的输入图像的区域；找感受野——找输出图像对应到输入中的区域；计算感受野【计算第i层输出结果的感受野，从RF(i)计算到RF(1):**RF(i)=S(i)(RF(i+1)-1)+K(i)**】;使用连续的小卷积核替换单个大卷积核，可以有效**降低网络训练的参数量**

![img](https://i2.hdslb.com/bfs/note/06158d491c29867d932e867d9372a67e02e6e3c1.jpg@690w_!web-note.webp)

![img](https://i2.hdslb.com/bfs/note/c79cecfdec5a1e30c77c44638ff73add64869bef.jpg@690w_!web-note.webp)

每一个卷积核都对应着一个feature map（输出）

**有多少个卷积核就有多少个feature map**

**Dilation——棋盘；表示卷积核不再是连续的一片，而是跨像素的感受野——可以获取更加有效的信息**

##### **2.多通道图片的卷积**

![img](https://i2.hdslb.com/bfs/note/6d614e38f3e3cd11629f2b8a9e5bbdb3950ff841.jpg@690w_!web-note.webp)

红的权重跟红色通道的input进行卷积，蓝的权重跟蓝色通道的input进行卷积，绿的权重跟绿色通道的input进行卷积；相当于一个三阶魔方在input进行滑动，这个三阶魔方的所有的卷积操作乘积作为最终的feature map

![img](https://i2.hdslb.com/bfs/note/264e087e1b8f137ff128f769190c363861fc3ced.jpg@690w_!web-note.webp)

![img](https://i2.hdslb.com/bfs/note/c10426dc065f1ec14dbb586930fd7f0886bd6452.jpg@690w_!web-note.webp)

{最左边的是原始图像（输入），第二列是第一个卷积核，进行卷积过后生成最右边上面的feature map，同理第三列的卷积核对最左边的input进行卷积过后生成最右边第二个的feature map}

![img](https://i2.hdslb.com/bfs/note/953debd208968844574771d14b0f4f1069fa12bb.jpg@690w_!web-note.webp)

卷积的目的——提取图像上的特征

![img](https://i2.hdslb.com/bfs/note/600a7df67c69d397ecebec56a62c3d9be1f42532.jpg@690w_!web-note.webp)

卷积核是通过人工智能、机器学习、梯度下降等方法自己找到的，并非人工设置

##### **3.池化**

![img](https://i2.hdslb.com/bfs/note/23d307f7b27b27dd4657804f526cf9a9355d24fc.jpg@690w_!web-note.webp)

每一个大框只选择一个作为其代表值，最大池化就是选择最大值，平均池化就是选择平均值

池化又叫做下采样，相当于在大框中进行采样并选择一个值来代表它

本质——大的变成小的；模糊——防止过拟合

![img](https://i2.hdslb.com/bfs/note/6184ffc77f948c44d925ea03b85037b4bdba6fc0.jpg@690w_!web-note.webp)

作用三：为卷积神经网络带来平移不变性

![img](https://i2.hdslb.com/bfs/note/a9ce6590f7630040f81b6bb78659d4c0e2562333.jpg@690w_!web-note.webp)

把池化层拉平成一个常向量，最后喂给全连接神经网络；全连接神经网络：每一层和上一层的所有神经元相连，密集连接

![img](https://i2.hdslb.com/bfs/note/41875a96687a0fe4e60515678bffc0741c076a9c.jpg@690w_!web-note.webp)

##### **4.卷积神经网络的结构——各层作用**

![img](https://i2.hdslb.com/bfs/note/1c8d6cc486be6345b2de6a0f9a5bbc142dc976b1.jpg@690w_!web-note.webp)

如上图例子，在卷积眼睛的时候，碰到眼睛就会在feature map显示100，否则就会变成0

——>用卷积核可以对图像的底层特征进行抽取，神经网络最后学习到的就是如何布置卷积核，相当于机器学习学出来时用哪个卷积核更加好

![img](https://i2.hdslb.com/bfs/note/086b2dc1417b9b501ffeb4814f12f2f14de7aaf8.jpg@690w_!web-note.webp)

![img](https://i2.hdslb.com/bfs/note/583c5ef6dfd5ad9cef10793131c4be796f916ead.jpg@690w_!web-note.webp)

从上图中可以得出：池化可以带来卷积神经网络的**平移不变性**

![img](https://i2.hdslb.com/bfs/note/ef2fcbea0e9575132b6d514a3019ad606f1e95b9.jpg@690w_!web-note.webp)

https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks-e3f054dd5daa

##### **5.结构解析**

![img](https://i2.hdslb.com/bfs/note/165ddffea1ea4aad54e7b641b275b55fea73c904.jpg@690w_!web-note.webp)

其实本质也是函数

![img](https://i2.hdslb.com/bfs/note/65baa202bda1f2c06753db603ecf28e352f86360.jpg@690w_!web-note.webp)

**CNN三大结构特性**

**（1）局部连接——感受野**

​		局部连接能够大大减少网络的参数。让每个神经元只与输入数据的一个局部区域连接，该连接的空间大小叫做神经元的感受野，它的尺寸是一个超参数，其实就是滤波器的空间尺寸。

**（2）权值共享——卷积**

​		 在卷积层中使用参数共享是用来控制参数的数量。每个滤波器与上一层局部相连，同时每个滤波器的所有局部连接都使用同样的参数——>大大减少网络的参数

**（3）空间或者时间上的下采样——池化pooling**

​		作用：逐渐降低数据的空间尺寸，减少网络中参数的数量，使得计算资源耗费变少，有效控制过拟合

![img](https://i2.hdslb.com/bfs/note/c75e6f97ccb9295fdd44efc33dd8ab7fb69cb334.jpg@690w_!web-note.webp)