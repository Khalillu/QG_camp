{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T06:53:05.224208Z",
     "start_time": "2025-07-07T06:53:05.121118Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dataloader import iris_dataloader\n",
    "\n",
    "\n",
    "# 初始化神经网络模型\n",
    "\n",
    "class NN(nn.Module):\n",
    "    # 将输入层、隐藏层、输出层的维度输入进神经网络模型中\n",
    "    def __init__(self, in_dim, hidden_dim1, hidden_dim2, out_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, hidden_dim1)\n",
    "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.layer3 = nn.Linear(hidden_dim2, out_dim)\n",
    "\n",
    "    #定义前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义计算环境\n",
    "\n",
    "\n",
    "device = torch.device(\"cude:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 训练集，验证集和测试集\n",
    "\n",
    "custom_dataset = iris_dataloader(\"D:\\\\Pycharm\\\\PyCharm 2024.3.1.1\\\\Pytorch实战\\\\iris.txt\")\n",
    "\n",
    "# 划分数据集\n",
    "train_size = int(len(custom_dataset) * 0.7)\n",
    "val_size = int(len(custom_dataset) * 0.2)\n",
    "# or test_size = int(len(custom_dataset)) - train_size - val_size\n",
    "test_size = int(len(custom_dataset) * 0.1)\n",
    "\n",
    "# random_split 按比例的随机切分，两个参数，一个是需要切分的数据集，一个是划分数据集的比例\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(custom_dataset,\n",
    "                                                                         [train_size, val_size, test_size])\n",
    "\n",
    "# shuffle=True作用：在batch抽取一定量数据集出来之后，将数据集进行打乱\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"训练集的大小\", train_size, \"验证集的大小\", val_size, \"测试集的大小\", test_size)\n",
    "\n",
    "\n",
    "# 定义一个推理函数，来计算并返回准确率\n",
    "\n",
    "def infer(self, model, dataset, device):\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    # 仅验证当前模型的性能，并不改变模型的参数\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            datas, label = data\n",
    "            # 该模型的返回结果（三种鸢尾花的可能性）\n",
    "            outputs = model(data.to(device))\n",
    "            #此时第零维为batch维度，即训练数据的数量，第一维才是结果维度，即鸢尾花的可能性\n",
    "            # 该函数返回一个元组，其中包含两个元素，第一个元素是最大值（每个样本的最大分数），第二个元素是最大值所在的索引（每个样本预测的类别索引），因此[1]代表我们只取索引部分，即预测的类别标签\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            # 比较当前模型的预测结果(predicct_y)与真实结果（label.to(device)）\n",
    "            # 由于每一次都是一批量数据加入该函数中，因此我们需要sum().item()来获取这一批量数据中预测正确的个数，而+=是对每一批量加起来的全部数据的预测个数，而item()则是让我们取到该结果的数值，即数量\n",
    "            acc_num += torch.eq(predict_y, label.to(device)).sum().item()\n",
    "\n",
    "    acc = acc_num / len(dataset)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def main(self, lr=0.005, epochs=20):\n",
    "    model = NN(4, 12, 6, 3).to(device)\n",
    "    loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "    # model.parameters()将会调用模型中的所有参数，if语句判断是否为可迭代的参数 如果p.requires_grad为True，则进入该列表中\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(pg, lr=lr)\n",
    "\n",
    "    # 权重文件存储路径，getcwd()将会获取目前文件夹的路径\n",
    "    save_path = os.path.join(os.getcwd(), \"results/weights\")\n",
    "    if os.path.exists(save_path) is False:\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # 开始训练\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        acc_num = torch.zeros(1).to(device)\n",
    "        sample_num = 0\n",
    "\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout, ncols=100)\n",
    "        for datas in train_bar:\n",
    "            data, label = datas\n",
    "            # 移除标签张量中大小为1的最后一个维度，(-1)表示指定要挤压（移除）的维度位置\n",
    "            label = label.squeeze(-1)\n",
    "            sample_num += data.shape[0]\n",
    "\n",
    "            # 防止以前的梯度，对当前产生一些影响\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data.to(device))\n",
    "            pred_class = torch.max(outputs, dim=1)[1]\n",
    "            acc_num = torch.eq(pred_class, label.to(device)).sum()\n",
    "\n",
    "            loss = loss_f(outputs, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc = acc_num / sample_num\n",
    "            train_bar.desc = \"train rpoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "\n",
    "        val_acc = infer(model, val_loader, device)\n",
    "        print(\"train epoch[{}/{}] loss:{:.3f} train_acc{:.3f}\".format(epoch + 1, epochs, loss, train_acc))\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, \"nn.pth\"))\n",
    "\n",
    "        # 每次数据集迭代之后，要对初始化的指标清零\n",
    "        train_acc = 0.\n",
    "        val_acc = 0.\n",
    "    print(\"Finished Training!\")\n",
    "\n",
    "    test_acc = infer(model, test_loader, device)\n",
    "    print(\"test_acc\", test_acc)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['1 5.1 3.5 1.4 0.2 \"setosa\"2 4.9 3 1.4 0.2 \"setosa\"3 4.7 3.2 1.3 0.2 \"setosa\"4 4.6 3.1 1.5 0.2 \"setosa\"5 5 3.6 1.4 0.2 \"setosa\"6 5.4 3.9 1.7 0.4 \"setosa\"7 4.6 3.4 1.4 0.3 \"setosa\"8 5 3.4 1.5 0.2 \"setosa\"9 4.4 2.9 1.4 0.2 \"setosa\"10 4.9 3.1 1.5 0.1 \"setosa\"11 5.4 3.7 1.5 0.2 \"setosa\"12 4.8 3.4 1.6 0.2 \"setosa\"13 4.8 3 1.4 0.1 \"setosa\"14 4.3 3 1.1 0.1 \"setosa\"15 5.8 4 1.2 0.2 \"setosa\"16 5.7 4.4 1.5 0.4 \"setosa\"17 5.4 3.9 1.3 0.4 \"setosa\"18 5.1 3.5 1.4 0.3 \"setosa\"19 5.7 3.8 1.7 0.3 \"setosa\"20 5.1 3.8 1.5 0.3 \"setosa\"21 5.4 3.4 1.7 0.2 \"setosa\"22 5.1 3.7 1.5 0.4 \"setosa\"23 4.6 3.6 1 0.2 \"setosa\"24 5.1 3.3 1.7 0.5 \"setosa\"25 4.8 3.4 1.9 0.2 \"setosa\"26 5 3 1.6 0.2 \"setosa\"27 5 3.4 1.6 0.4 \"setosa\"28 5.2 3.5 1.5 0.2 \"setosa\"29 5.2 3.4 1.4 0.2 \"setosa\"30 4.7 3.2 1.6 0.2 \"setosa\"31 4.8 3.1 1.6 0.2 \"setosa\"32 5.4 3.4 1.5 0.4 \"setosa\"33 5.2 4.1 1.5 0.1 \"setosa\"34 5.5 4.2 1.4 0.2 \"setosa\"35 4.9 3.1 1.5 0.2 \"setosa\"36 5 3.2 1.2 0.2 \"setosa\"37 5.5 3.5 1.3 0.2 \"setosa\"38 4.9 3.6 1.4 0.1 \"setosa\"39 4.4 3 1.3 0.2 \"setosa\"40 5.1 3.4 1.5 0.2 \"setosa\"41 5 3.5 1.3 0.3 \"setosa\"42 4.5 2.3 1.3 0.3 \"setosa\"43 4.4 3.2 1.3 0.2 \"setosa\"44 5 3.5 1.6 0.6 \"setosa\"45 5.1 3.8 1.9 0.4 \"setosa\"46 4.8 3 1.4 0.3 \"setosa\"47 5.1 3.8 1.6 0.2 \"setosa\"48 4.6 3.2 1.4 0.2 \"setosa\"49 5.3 3.7 1.5 0.2 \"setosa\"50 5 3.3 1.4 0.2 \"setosa\"51 7 3.2 4.7 1.4 \"versicolor\"52 6.4 3.2 4.5 1.5 \"versicolor\"53 6.9 3.1 4.9 1.5 \"versicolor\"54 5.5 2.3 4 1.3 \"versicolor\"55 6.5 2.8 4.6 1.5 \"versicolor\"56 5.7 2.8 4.5 1.3 \"versicolor\"57 6.3 3.3 4.7 1.6 \"versicolor\"58 4.9 2.4 3.3 1 \"versicolor\"59 6.6 2.9 4.6 1.3 \"versicolor\"60 5.2 2.7 3.9 1.4 \"versicolor\"61 5 2 3.5 1 \"versicolor\"62 5.9 3 4.2 1.5 \"versicolor\"63 6 2.2 4 1 \"versicolor\"64 6.1 2.9 4.7 1.4 \"versicolor\"65 5.6 2.9 3.6 1.3 \"versicolor\"66 6.7 3.1 4.4 1.4 \"versicolor\"67 5.6 3 4.5 1.5 \"versicolor\"68 5.8 2.7 4.1 1 \"versicolor\"69 6.2 2.2 4.5 1.5 \"versicolor\"70 5.6 2.5 3.9 1.1 \"versicolor\"71 5.9 3.2 4.8 1.8 \"versicolor\"72 6.1 2.8 4 1.3 \"versicolor\"73 6.3 2.5 4.9 1.5 \"versicolor\"74 6.1 2.8 4.7 1.2 \"versicolor\"75 6.4 2.9 4.3 1.3 \"versicolor\"76 6.6 3 4.4 1.4 \"versicolor\"77 6.8 2.8 4.8 1.4 \"versicolor\"78 6.7 3 5 1.7 \"versicolor\"79 6 2.9 4.5 1.5 \"versicolor\"80 5.7 2.6 3.5 1 \"versicolor\"81 5.5 2.4 3.8 1.1 \"versicolor\"82 5.5 2.4 3.7 1 \"versicolor\"83 5.8 2.7 3.9 1.2 \"versicolor\"84 6 2.7 5.1 1.6 \"versicolor\"85 5.4 3 4.5 1.5 \"versicolor\"86 6 3.4 4.5 1.6 \"versicolor\"87 6.7 3.1 4.7 1.5 \"versicolor\"88 6.3 2.3 4.4 1.3 \"versicolor\"89 5.6 3 4.1 1.3 \"versicolor\"90 5.5 2.5 4 1.3 \"versicolor\"91 5.5 2.6 4.4 1.2 \"versicolor\"92 6.1 3 4.6 1.4 \"versicolor\"93 5.8 2.6 4 1.2 \"versicolor\"94 5 2.3 3.3 1 \"versicolor\"95 5.6 2.7 4.2 1.3 \"versicolor\"96 5.7 3 4.2 1.2 \"versicolor\"97 5.7 2.9 4.2 1.3 \"versicolor\"98 6.2 2.9 4.3 1.3 \"versicolor\"99 5.1 2.5 3 1.1 \"versicolor\"100 5.7 2.8 4.1 1.3 \"versicolor\"101 6.3 3.3 6 2.5 \"virginica\"102 5.8 2.7 5.1 1.9 \"virginica\"103 7.1 3 5.9 2.1 \"virginica\"104 6.3 2.9 5.6 1.8 \"virginica\"105 6.5 3 5.8 2.2 \"virginica\"106 7.6 3 6.6 2.1 \"virginica\"107 4.9 2.5 4.5 1.7 \"virginica\"108 7.3 2.9 6.3 1.8 \"virginica\"109 6.7 2.5 5.8 1.8 \"virginica\"110 7.2 3.6 6.1 2.5 \"virginica\"111 6.5 3.2 5.1 2 \"virginica\"112 6.4 2.7 5.3 1.9 \"virginica\"113 6.8 3 5.5 2.1 \"virginica\"114 5.7 2.5 5 2 \"virginica\"115 5.8 2.8 5.1 2.4 \"virginica\"116 6.4 3.2 5.3 2.3 \"virginica\"117 6.5 3 5.5 1.8 \"virginica\"118 7.7 3.8 6.7 2.2 \"virginica\"119 7.7 2.6 6.9 2.3 \"virginica\"120 6 2.2 5 1.5 \"virginica\"121 6.9 3.2 5.7 2.3 \"virginica\"122 5.6 2.8 4.9 2 \"virginica\"123 7.7 2.8 6.7 2 \"virginica\"124 6.3 2.7 4.9 1.8 \"virginica\"125 6.7 3.3 5.7 2.1 \"virginica\"126 7.2 3.2 6 1.8 \"virginica\"127 6.2 2.8 4.8 1.8 \"virginica\"128 6.1 3 4.9 1.8 \"virginica\"129 6.4 2.8 5.6 2.1 \"virginica\"130 7.2 3 5.8 1.6 \"virginica\"131 7.4 2.8 6.1 1.9 \"virginica\"132 7.9 3.8 6.4 2 \"virginica\"133 6.4 2.8 5.6 2.2 \"virginica\"134 6.3 2.8 5.1 1.5 \"virginica\"135 6.1 2.6 5.6 1.4 \"virginica\"136 7.7 3 6.1 2.3 \"virginica\"137 6.3 3.4 5.6 2.4 \"virginica\"138 6.4 3.1 5.5 1.8 \"virginica\"139 6 3 4.8 1.8 \"virginica\"140 6.9 3.1 5.4 2.1 \"virginica\"141 6.7 3.1 5.6 2.4 \"virginica\"142 6.9 3.1 5.1 2.3 \"virginica\"143 5.8 2.7 5.1 1.9 \"virginica\"144 6.8 3.2 5.9 2.3 \"virginica\"145 6.7 3.3 5.7 2.5 \"virginica\"146 6.7 3 5.2 2.3 \"virginica\"147 6.3 2.5 5 1.9 \"virginica\"148 6.5 3 5.2 2 \"virginica\"149 6.2 3.4 5.4 2.3 \"virginica\"150 5.9 3 5.1 1.8 \"virginica\"'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 36\u001B[0m\n\u001B[0;32m     32\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcude:0\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# 训练集，验证集和测试集\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m custom_dataset \u001B[38;5;241m=\u001B[39m iris_dataloader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mD:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPycharm\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPyCharm 2024.3.1.1\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPytorch实战\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124miris.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# 划分数据集\u001B[39;00m\n\u001B[0;32m     39\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(custom_dataset) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.7\u001B[39m)\n",
      "File \u001B[1;32mD:\\Pycharm\\PyCharm 2024.3.1.1\\Pytorch实战\\dataloader.py:31\u001B[0m, in \u001B[0;36miris_dataloader.__init__\u001B[1;34m(self, data_path)\u001B[0m\n\u001B[0;32m     26\u001B[0m label \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m1\u001B[39m:,\u001B[38;5;241m4\u001B[39m:]\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# 由于pandas的数据类型dataframe不能与pytorch兼容，因此不能直接使用，需要转化为numpy数组之后，再转化为torch中的张量tenser类型\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# 将数据集中的数值映射到均值为零，方差为1的数据分布中\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m mean \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(data, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     32\u001B[0m std \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstd(data, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     33\u001B[0m data \u001B[38;5;241m=\u001B[39m (data \u001B[38;5;241m-\u001B[39m mean) \u001B[38;5;241m/\u001B[39m std \u001B[38;5;66;03m# Z值化\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3902\u001B[0m, in \u001B[0;36mmean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m   3900\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   3901\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3902\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   3904\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _methods\u001B[38;5;241m.\u001B[39m_mean(a, axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   3905\u001B[0m                       out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\frame.py:11693\u001B[0m, in \u001B[0;36mDataFrame.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  11685\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m  11686\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  11687\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  11691\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  11692\u001B[0m ):\n\u001B[1;32m> 11693\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mmean(axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m  11694\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, Series):\n\u001B[0;32m  11695\u001B[0m         result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001B[0m, in \u001B[0;36mNDFrame.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12413\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  12414\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12415\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12418\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12419\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m> 12420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  12421\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, nanops\u001B[38;5;241m.\u001B[39mnanmean, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m  12422\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12373\u001B[0m nv\u001B[38;5;241m.\u001B[39mvalidate_func(name, (), kwargs)\n\u001B[0;32m  12375\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reduce(\n\u001B[0;32m  12378\u001B[0m     func, name\u001B[38;5;241m=\u001B[39mname, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only\n\u001B[0;32m  12379\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001B[0m, in \u001B[0;36mDataFrame._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m  11558\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m  11560\u001B[0m \u001B[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001B[39;00m\n\u001B[0;32m  11561\u001B[0m \u001B[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001B[39;00m\n\u001B[1;32m> 11562\u001B[0m res \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mreduce(blk_func)\n\u001B[0;32m  11563\u001B[0m out \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(res, axes\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39maxes)\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m  11564\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m out\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboolean\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001B[0m, in \u001B[0;36mBlockManager.reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m   1498\u001B[0m res_blocks: \u001B[38;5;28mlist\u001B[39m[Block] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[1;32m-> 1500\u001B[0m     nbs \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mreduce(func)\n\u001B[0;32m   1501\u001B[0m     res_blocks\u001B[38;5;241m.\u001B[39mextend(nbs)\n\u001B[0;32m   1503\u001B[0m index \u001B[38;5;241m=\u001B[39m Index([\u001B[38;5;28;01mNone\u001B[39;00m])  \u001B[38;5;66;03m# placeholder\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001B[0m, in \u001B[0;36mBlock.reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Block]:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001B[39;00m\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001B[39;00m\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m--> 404\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    407\u001B[0m         res_values \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001B[0m, in \u001B[0;36mDataFrame._reduce.<locals>.blk_func\u001B[1;34m(values, axis)\u001B[0m\n\u001B[0;32m  11479\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([result])\n\u001B[0;32m  11480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m> 11481\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m op(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    145\u001B[0m         result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m func(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, mask\u001B[38;5;241m=\u001B[39mmask, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[0;32m    407\u001B[0m     result \u001B[38;5;241m=\u001B[39m _wrap_results(result, orig_values\u001B[38;5;241m.\u001B[39mdtype, fill_value\u001B[38;5;241m=\u001B[39miNaT)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001B[0m, in \u001B[0;36mnanmean\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m    718\u001B[0m count \u001B[38;5;241m=\u001B[39m _get_counts(values\u001B[38;5;241m.\u001B[39mshape, mask, axis, dtype\u001B[38;5;241m=\u001B[39mdtype_count)\n\u001B[0;32m    719\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39msum(axis, dtype\u001B[38;5;241m=\u001B[39mdtype_sum)\n\u001B[1;32m--> 720\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m _ensure_numeric(the_sum)\n\u001B[0;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(the_sum, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    723\u001B[0m     count \u001B[38;5;241m=\u001B[39m cast(np\u001B[38;5;241m.\u001B[39mndarray, count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\core\\nanops.py:1686\u001B[0m, in \u001B[0;36m_ensure_numeric\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1683\u001B[0m inferred \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39minfer_dtype(x)\n\u001B[0;32m   1684\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inferred \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstring\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m   1685\u001B[0m     \u001B[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001B[39;00m\n\u001B[1;32m-> 1686\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not convert \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to numeric\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1688\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mcomplex128)\n",
      "\u001B[1;31mTypeError\u001B[0m: Could not convert ['1 5.1 3.5 1.4 0.2 \"setosa\"2 4.9 3 1.4 0.2 \"setosa\"3 4.7 3.2 1.3 0.2 \"setosa\"4 4.6 3.1 1.5 0.2 \"setosa\"5 5 3.6 1.4 0.2 \"setosa\"6 5.4 3.9 1.7 0.4 \"setosa\"7 4.6 3.4 1.4 0.3 \"setosa\"8 5 3.4 1.5 0.2 \"setosa\"9 4.4 2.9 1.4 0.2 \"setosa\"10 4.9 3.1 1.5 0.1 \"setosa\"11 5.4 3.7 1.5 0.2 \"setosa\"12 4.8 3.4 1.6 0.2 \"setosa\"13 4.8 3 1.4 0.1 \"setosa\"14 4.3 3 1.1 0.1 \"setosa\"15 5.8 4 1.2 0.2 \"setosa\"16 5.7 4.4 1.5 0.4 \"setosa\"17 5.4 3.9 1.3 0.4 \"setosa\"18 5.1 3.5 1.4 0.3 \"setosa\"19 5.7 3.8 1.7 0.3 \"setosa\"20 5.1 3.8 1.5 0.3 \"setosa\"21 5.4 3.4 1.7 0.2 \"setosa\"22 5.1 3.7 1.5 0.4 \"setosa\"23 4.6 3.6 1 0.2 \"setosa\"24 5.1 3.3 1.7 0.5 \"setosa\"25 4.8 3.4 1.9 0.2 \"setosa\"26 5 3 1.6 0.2 \"setosa\"27 5 3.4 1.6 0.4 \"setosa\"28 5.2 3.5 1.5 0.2 \"setosa\"29 5.2 3.4 1.4 0.2 \"setosa\"30 4.7 3.2 1.6 0.2 \"setosa\"31 4.8 3.1 1.6 0.2 \"setosa\"32 5.4 3.4 1.5 0.4 \"setosa\"33 5.2 4.1 1.5 0.1 \"setosa\"34 5.5 4.2 1.4 0.2 \"setosa\"35 4.9 3.1 1.5 0.2 \"setosa\"36 5 3.2 1.2 0.2 \"setosa\"37 5.5 3.5 1.3 0.2 \"setosa\"38 4.9 3.6 1.4 0.1 \"setosa\"39 4.4 3 1.3 0.2 \"setosa\"40 5.1 3.4 1.5 0.2 \"setosa\"41 5 3.5 1.3 0.3 \"setosa\"42 4.5 2.3 1.3 0.3 \"setosa\"43 4.4 3.2 1.3 0.2 \"setosa\"44 5 3.5 1.6 0.6 \"setosa\"45 5.1 3.8 1.9 0.4 \"setosa\"46 4.8 3 1.4 0.3 \"setosa\"47 5.1 3.8 1.6 0.2 \"setosa\"48 4.6 3.2 1.4 0.2 \"setosa\"49 5.3 3.7 1.5 0.2 \"setosa\"50 5 3.3 1.4 0.2 \"setosa\"51 7 3.2 4.7 1.4 \"versicolor\"52 6.4 3.2 4.5 1.5 \"versicolor\"53 6.9 3.1 4.9 1.5 \"versicolor\"54 5.5 2.3 4 1.3 \"versicolor\"55 6.5 2.8 4.6 1.5 \"versicolor\"56 5.7 2.8 4.5 1.3 \"versicolor\"57 6.3 3.3 4.7 1.6 \"versicolor\"58 4.9 2.4 3.3 1 \"versicolor\"59 6.6 2.9 4.6 1.3 \"versicolor\"60 5.2 2.7 3.9 1.4 \"versicolor\"61 5 2 3.5 1 \"versicolor\"62 5.9 3 4.2 1.5 \"versicolor\"63 6 2.2 4 1 \"versicolor\"64 6.1 2.9 4.7 1.4 \"versicolor\"65 5.6 2.9 3.6 1.3 \"versicolor\"66 6.7 3.1 4.4 1.4 \"versicolor\"67 5.6 3 4.5 1.5 \"versicolor\"68 5.8 2.7 4.1 1 \"versicolor\"69 6.2 2.2 4.5 1.5 \"versicolor\"70 5.6 2.5 3.9 1.1 \"versicolor\"71 5.9 3.2 4.8 1.8 \"versicolor\"72 6.1 2.8 4 1.3 \"versicolor\"73 6.3 2.5 4.9 1.5 \"versicolor\"74 6.1 2.8 4.7 1.2 \"versicolor\"75 6.4 2.9 4.3 1.3 \"versicolor\"76 6.6 3 4.4 1.4 \"versicolor\"77 6.8 2.8 4.8 1.4 \"versicolor\"78 6.7 3 5 1.7 \"versicolor\"79 6 2.9 4.5 1.5 \"versicolor\"80 5.7 2.6 3.5 1 \"versicolor\"81 5.5 2.4 3.8 1.1 \"versicolor\"82 5.5 2.4 3.7 1 \"versicolor\"83 5.8 2.7 3.9 1.2 \"versicolor\"84 6 2.7 5.1 1.6 \"versicolor\"85 5.4 3 4.5 1.5 \"versicolor\"86 6 3.4 4.5 1.6 \"versicolor\"87 6.7 3.1 4.7 1.5 \"versicolor\"88 6.3 2.3 4.4 1.3 \"versicolor\"89 5.6 3 4.1 1.3 \"versicolor\"90 5.5 2.5 4 1.3 \"versicolor\"91 5.5 2.6 4.4 1.2 \"versicolor\"92 6.1 3 4.6 1.4 \"versicolor\"93 5.8 2.6 4 1.2 \"versicolor\"94 5 2.3 3.3 1 \"versicolor\"95 5.6 2.7 4.2 1.3 \"versicolor\"96 5.7 3 4.2 1.2 \"versicolor\"97 5.7 2.9 4.2 1.3 \"versicolor\"98 6.2 2.9 4.3 1.3 \"versicolor\"99 5.1 2.5 3 1.1 \"versicolor\"100 5.7 2.8 4.1 1.3 \"versicolor\"101 6.3 3.3 6 2.5 \"virginica\"102 5.8 2.7 5.1 1.9 \"virginica\"103 7.1 3 5.9 2.1 \"virginica\"104 6.3 2.9 5.6 1.8 \"virginica\"105 6.5 3 5.8 2.2 \"virginica\"106 7.6 3 6.6 2.1 \"virginica\"107 4.9 2.5 4.5 1.7 \"virginica\"108 7.3 2.9 6.3 1.8 \"virginica\"109 6.7 2.5 5.8 1.8 \"virginica\"110 7.2 3.6 6.1 2.5 \"virginica\"111 6.5 3.2 5.1 2 \"virginica\"112 6.4 2.7 5.3 1.9 \"virginica\"113 6.8 3 5.5 2.1 \"virginica\"114 5.7 2.5 5 2 \"virginica\"115 5.8 2.8 5.1 2.4 \"virginica\"116 6.4 3.2 5.3 2.3 \"virginica\"117 6.5 3 5.5 1.8 \"virginica\"118 7.7 3.8 6.7 2.2 \"virginica\"119 7.7 2.6 6.9 2.3 \"virginica\"120 6 2.2 5 1.5 \"virginica\"121 6.9 3.2 5.7 2.3 \"virginica\"122 5.6 2.8 4.9 2 \"virginica\"123 7.7 2.8 6.7 2 \"virginica\"124 6.3 2.7 4.9 1.8 \"virginica\"125 6.7 3.3 5.7 2.1 \"virginica\"126 7.2 3.2 6 1.8 \"virginica\"127 6.2 2.8 4.8 1.8 \"virginica\"128 6.1 3 4.9 1.8 \"virginica\"129 6.4 2.8 5.6 2.1 \"virginica\"130 7.2 3 5.8 1.6 \"virginica\"131 7.4 2.8 6.1 1.9 \"virginica\"132 7.9 3.8 6.4 2 \"virginica\"133 6.4 2.8 5.6 2.2 \"virginica\"134 6.3 2.8 5.1 1.5 \"virginica\"135 6.1 2.6 5.6 1.4 \"virginica\"136 7.7 3 6.1 2.3 \"virginica\"137 6.3 3.4 5.6 2.4 \"virginica\"138 6.4 3.1 5.5 1.8 \"virginica\"139 6 3 4.8 1.8 \"virginica\"140 6.9 3.1 5.4 2.1 \"virginica\"141 6.7 3.1 5.6 2.4 \"virginica\"142 6.9 3.1 5.1 2.3 \"virginica\"143 5.8 2.7 5.1 1.9 \"virginica\"144 6.8 3.2 5.9 2.3 \"virginica\"145 6.7 3.3 5.7 2.5 \"virginica\"146 6.7 3 5.2 2.3 \"virginica\"147 6.3 2.5 5 1.9 \"virginica\"148 6.5 3 5.2 2 \"virginica\"149 6.2 3.4 5.4 2.3 \"virginica\"150 5.9 3 5.1 1.8 \"virginica\"'] to numeric"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c016e51c761b1652"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
